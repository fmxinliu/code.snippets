{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4876aae",
   "metadata": {},
   "source": [
    "# 原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59660f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "x = np.random.uniform(-3, 3, size=100)\n",
    "X = x.reshape(-1, 1)\n",
    "y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3716aa",
   "metadata": {},
   "source": [
    "# 拟合\n",
    "## 使用线性回归拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f96b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X, y)\n",
    "y_predict = linear_regression.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea64d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_predict, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a28a7",
   "metadata": {},
   "source": [
    "## 使用多项式回归拟合\n",
    "### 转换为线性回归\n",
    "- y = ax**2 + bx + c 看成是: y = ax1 + bx2 + c, X = [x1, x2], 训练模型求合适的系数 a、b、c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c69c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.hstack([X**2, X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07bb47c",
   "metadata": {},
   "source": [
    "### 线性回归训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b92d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression2 = LinearRegression()\n",
    "linear_regression2.fit(X2, y)\n",
    "y_predict2 = linear_regression2.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb07419",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y_predict2[np.argsort(x)], color='r')  # x从小到大的顺序\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcae5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4373b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression2.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac197698",
   "metadata": {},
   "source": [
    "## Polynomial回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2fd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def PolynomialRegression(degree=2):\n",
    "    \"\"\"多项式回归\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"ploy\", PolynomialFeatures(degree)),    # 1.转换为线性回归, degree: 多项式的阶数\n",
    "        (\"std_scaler\", StandardScaler()),        # 2.数据集归一化\n",
    "        (\"linear_reg\", LinearRegression())       # 3.线性回归\n",
    "    ])\n",
    "\n",
    "\n",
    "def PolynomialRegressionTest(degree=2):\n",
    "    # 多项式拟合\n",
    "    ploy_regression = PolynomialRegression(degree=degree)\n",
    "    ploy_regression.fit(X, y)\n",
    "    y_predict = ploy_regression.predict(X)\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "#     plt.plot(np.sort(x), y_predict[np.argsort(x)], color='g')  # x从小到大的顺序\n",
    "\n",
    "    # 绘制真实的拟合曲线\n",
    "    X_plot = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "    y_plot = ploy_regression.predict(X_plot)\n",
    "    plt.plot(X_plot, y_plot, color='r')\n",
    "    plt.axis([-3, 3, -1, 10])\n",
    "    plt.show()\n",
    "\n",
    "    # MSE\n",
    "    print(mean_squared_error(y, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a596d8c",
   "metadata": {},
   "source": [
    "# 模型泛化能力\n",
    "## 欠拟合和过拟合\n",
    "- 欠拟合： 在训练集和测试集上表现都不好。一般是样本量过少训练不足，导致模型过于简单，偏差较大\n",
    "- 过拟合： 在训练集上表现好，在测试集上表现不好。一般是噪音或无用的特征参与了训练，导致模型过于复杂，方差较大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f59f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4583631",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef96920",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da028540",
   "metadata": {},
   "source": [
    "## 学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def plot_learning_curve(algo, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"绘制学习曲线\"\"\"\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1, len(X_train)+1):\n",
    "        algo.fit(X_train[:i], y_train[:i])\n",
    "\n",
    "        y_train_predict = algo.predict(X_train[:i])\n",
    "        train_score.append(mean_squared_error(y_train[:i], y_train_predict))\n",
    "\n",
    "        y_test_predict = algo.predict(X_test)\n",
    "        test_score.append(mean_squared_error(y_test, y_test_predict))\n",
    "\n",
    "    plt.plot([i for i in range(1, len(X_train)+1)], np.sqrt(train_score), label='train')\n",
    "    plt.plot([i for i in range(1, len(X_train)+1)], np.sqrt(test_score), label='test')\n",
    "    plt.legend()\n",
    "    plt.axis([0, len(X_train)+1, 0, 4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aa75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(LinearRegression(), X_train, X_test, y_train, y_test)  # 欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(PolynomialRegression(), X_train, X_test, y_train, y_test)  # ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a862184",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(PolynomialRegression(degree=20), X_train, X_test, y_train, y_test) # 过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934cce4",
   "metadata": {},
   "source": [
    "## 交叉验证\n",
    "- 使用train_test_split后的数据集来训练模型，结果有可能过拟合测试数据，一般使用交叉验证来训练模型：\n",
    "  - 1.将train_test_split后的训练集划分为：训练集+验证集，进行模型训练，获取最佳的超参数\n",
    "  - 2.测试模型在测试集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def train_test(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"使用训练集和测试集训练模型(结果仍有可能过拟合)\"\"\"\n",
    "    best_score, best_p, best_k = 0, 0, 0\n",
    "    for k in range(2, 6):\n",
    "        for p in range(1, 5):\n",
    "            knn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=k, p=p)\n",
    "            knn_clf.fit(X_train, y_train)\n",
    "            score = knn_clf.score(X_test, y_test)\n",
    "            if score > best_score:\n",
    "                best_score, best_p, best_k = score, p, k\n",
    "\n",
    "    print(\"best k = \", best_k)\n",
    "    print(\"best p = \", best_p)\n",
    "    print(\"best score = \", best_score)\n",
    "    \n",
    "\n",
    "def train_validate_test(X_train, X_test, y_train, y_test, cv=3):\n",
    "    \"\"\"\n",
    "    1.使用交叉验证获取最佳的超参数，\n",
    "    2.用最佳的超参数训练模型，测试模型在测试集上的表现\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1.使用交叉验证获取最佳的超参数\n",
    "    best_score, best_p, best_k = 0, 0, 0\n",
    "    for k in range(2, 6):\n",
    "        for p in range(1, 5):\n",
    "            knn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=k, p=p)\n",
    "            scores = cross_val_score(knn_clf, X_train, y_train, cv=cv)\n",
    "            score = np.mean(scores)\n",
    "            if score > best_score:\n",
    "                best_score, best_p, best_k = score, p, k\n",
    "\n",
    "    print(\"best k = \", best_k)\n",
    "    print(\"best p = \", best_p)\n",
    "    print(\"best score = \", best_score)\n",
    "    \n",
    "    # 2.用最佳的超参数训练模型，测试模型在测试集上的表现\n",
    "    knn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=k, p=p)\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    print(\"final score = \", knn_clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "def test():\n",
    "    digits = load_digits()\n",
    "    X = digits.data\n",
    "    y = digits.target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10)\n",
    "    \n",
    "    train_test(X_train, X_test, y_train, y_test)\n",
    "    train_validate_test(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246a0b0",
   "metadata": {},
   "source": [
    "## 模型正则化\n",
    "- 解决过拟合问题。\n",
    "  - L1 正则化：高次项系数置0，直接去掉高次项。<--**Lasso回归**\n",
    "  - L2 正则化：高次项系数设为很小的值，弱化高次项带来的影响。<--**Ridge回归**\n",
    "  - 弹性网络 ：结合 L1、L2\n",
    "\n",
    "### Ridge回归\n",
    "- 损失函数：MSE + alpha * np.sum(theta ** 2)\n",
    "- alpha越大，theta越小，正则化力度越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787867d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def RidgeRegression(degree=2, alpha=0.0001):\n",
    "    \"\"\"Ridge回归\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"ploy\", PolynomialFeatures(degree)),    # 1.转换为线性回归, degree: 多项式的阶数\n",
    "        (\"std_scaler\", StandardScaler()),        # 2.数据集归一化\n",
    "        (\"ridge_reg\", Ridge(alpha=alpha))        # 3.Ridge回归\n",
    "    ])\n",
    "\n",
    "\n",
    "def RidgeRegressionTest(degree=2, alpha=0.0001):\n",
    "    # Ridge回归\n",
    "    ridge_regression = RidgeRegression(degree=degree, alpha=alpha)\n",
    "    ridge_regression.fit(X, y)\n",
    "    y_predict = ridge_regression.predict(X)\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "#     plt.plot(np.sort(x), y_predict[np.argsort(x)], color='g')  # x从小到大的顺序\n",
    "\n",
    "    # 绘制真实的拟合曲线\n",
    "    X_plot = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "    y_plot = ridge_regression.predict(X_plot)\n",
    "    plt.plot(X_plot, y_plot, color='r')\n",
    "    plt.axis([-3, 3, -1, 10])\n",
    "    plt.show()\n",
    "\n",
    "    # MSE\n",
    "    print(mean_squared_error(y, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e13363",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=100)  # 多项式回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeRegressionTest(degree=100, alpha=0.0001)  # 岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f64fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeRegressionTest(degree=100, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08762c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeRegressionTest(degree=100, alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1889644",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeRegressionTest(degree=100, alpha=1000000)  # 正则化过头"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef059c",
   "metadata": {},
   "source": [
    "### Lasso回归\n",
    "- 损失函数：MSE + alpha * np.abs(theta)\n",
    "- alpha越大，theta越小，正则化力度越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79002615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def LassoRegression(degree=2, alpha=0.01):\n",
    "    \"\"\"Lasso回归\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"ploy\", PolynomialFeatures(degree)),    # 1.转换为线性回归, degree: 多项式的阶数\n",
    "        (\"std_scaler\", StandardScaler()),        # 2.数据集归一化\n",
    "        (\"lasso_reg\", Lasso(alpha=alpha))        # 3.Lasso回归\n",
    "    ])\n",
    "\n",
    "\n",
    "def LassoRegressionTest(degree=2, alpha=0.01):\n",
    "    # Lasso回归\n",
    "    lasso_regression = LassoRegression(degree=degree, alpha=alpha)\n",
    "    lasso_regression.fit(X, y)\n",
    "    y_predict = lasso_regression.predict(X)\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "#     plt.plot(np.sort(x), y_predict[np.argsort(x)], color='g')  # x从小到大的顺序\n",
    "\n",
    "    # 绘制真实的拟合曲线\n",
    "    X_plot = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "    y_plot = lasso_regression.predict(X_plot)\n",
    "    plt.plot(X_plot, y_plot, color='r')\n",
    "    plt.axis([-3, 3, -1, 10])\n",
    "    plt.show()\n",
    "\n",
    "    # MSE\n",
    "    print(mean_squared_error(y, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd132511",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialRegressionTest(degree=100)  # 多项式回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoRegressionTest(degree=100, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoRegressionTest(degree=100, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afff728",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoRegressionTest(degree=100, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoRegressionTest(degree=100, alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8433b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "244.1px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
