{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.获取数据集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2.1.数据预处理，构建二分类数据\n",
    "X = X[y < 2, :2]\n",
    "y = y[y < 2]\n",
    "\n",
    "# 2.2.涉及求距离，注意对数据进行标准化处理\n",
    "standardScaler = StandardScaler()\n",
    "X_standard = standardScaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, axis):\n",
    "    \"\"\"绘制决策边界\"\"\"\n",
    "    x0, x1 = np.meshgrid(\n",
    "        np.linspace(axis[0], axis[1], int((axis[1]-axis[0])*100)),\n",
    "        np.linspace(axis[2], axis[3], int((axis[3]-axis[2])*100))\n",
    "    )\n",
    "    X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "    y_predict = model.predict(X_new)\n",
    "    zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    custom_cmap = ListedColormap(['#EF9A9A', '#FFF59D', '#90CAF9'])\n",
    "\n",
    "    plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "\n",
    "\n",
    "def plot_svc_decision_boundary(model, axis):\n",
    "    \"\"\"绘制SVC决策边界+支撑向量\"\"\"\n",
    "    plot_decision_boundary(model, axis)\n",
    "\n",
    "    # 绘制一条决策边界的支撑向量\n",
    "    w = model.coef_[0]\n",
    "    b = model.intercept_[0]\n",
    "\n",
    "    # w0 * x0 + w1 * x1 + b = 0\n",
    "    # => x1 = -w0/w1 * x0 - b/w1\n",
    "    plot_x = np.linspace(axis[0], axis[1], 200)\n",
    "    up_y = -w[0]/w[1] * plot_x - b/w[1] + 1/w[1]\n",
    "    down_y = -w[0]/w[1] * plot_x - b/w[1] - 1/w[1]\n",
    "\n",
    "    # 过滤 y，防止超出绘制范围\n",
    "    up_index = (up_y >= axis[2]) & (up_y <= axis[3])\n",
    "    down_index = (down_y >= axis[2]) & (down_y <= axis[3])\n",
    "\n",
    "    plt.plot(plot_x[up_index], up_y[up_index], color='black')\n",
    "    plt.plot(plot_x[down_index], down_y[down_index], color='black')\n",
    "\n",
    "\n",
    "def plot_scatter(X, y):\n",
    "    \"\"\"绘制数据点\"\"\"\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1])\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1])\n",
    "\n",
    "\n",
    "def linearsvcTest(X, y, C=1e9):\n",
    "    \"\"\"线性SVC\"\"\"\n",
    "    svc = LinearSVC(C=C, random_state=17)  # C越大，容错能力越小，不允许数据点落在支撑向量之间\n",
    "    svc.fit(X, y)\n",
    "\n",
    "    plot_svc_decision_boundary(svc, axis=[-3, 3, -3, 3])\n",
    "    plot_scatter(X, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Margin SVM\n",
    "- 会考虑每个数据点，要求数据是**线性可分的**，支持向量之间不允许有数据点\n",
    "- 个别的干扰数据点，会影响整体分类，降低模型泛化能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearsvcTest(X_standard, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Margin SVM\n",
    "- **引入超参数C**，调节容错范围(**容错边界，位于支撑向量内部**)，允许数据点落在支撑向量与容错边界之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearsvcTest(X_standard, y, C=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearsvcTest(X_standard, y, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearsvcTest(X_standard, y, C=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非线性SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(*datasets.make_moons())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_moons(noise=0.15, random_state=666)\n",
    "plot_scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用多项式特征的SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def PolynomialSVC(degree, C=1.0):\n",
    "    \"\"\"多项式SVC\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"ploy\", PolynomialFeatures(degree)),    # 1.转换为线性回归, degree: 多项式的阶数\n",
    "        (\"std_scaler\", StandardScaler()),        # 2.数据集标准化\n",
    "        (\"linear_svc\", LinearSVC(C=C))           # 3.线性SVM\n",
    "    ])\n",
    "\n",
    "\n",
    "def PolynomialSVCTest(degree, C=1.0):\n",
    "    poly_svc = PolynomialSVC(degree, C)\n",
    "    poly_svc.fit(X, y)\n",
    "    plot_decision_boundary(poly_svc, axis=[-1.5, 2.5, -1.0, 1.5])\n",
    "    plot_scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialSVCTest(degree=3, C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialSVCTest(degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialSVCTest(degree=3, C=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用多项式核函数的SVM\n",
    "- **引入超参数degree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def PolynomialKernelSVC(degree, C=1.0):\n",
    "    \"\"\"多项式核SVC\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"kernel_svc\", SVC(kernel=\"poly\", degree=degree, C=C))\n",
    "    ])\n",
    "\n",
    "\n",
    "def PolynomialKernelSVCTest(degree, C=1.0):\n",
    "    poly_kernel_svc = PolynomialKernelSVC(degree, C)\n",
    "    poly_kernel_svc.fit(X, y)\n",
    "    plot_decision_boundary(poly_kernel_svc, axis=[-1.5, 2.5, -1.0, 1.5])\n",
    "    plot_scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialKernelSVCTest(degree=3, C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialKernelSVCTest(degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialKernelSVCTest(degree=3, C=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用高斯核函数的SVM\n",
    "### 直观理解高斯核函数\n",
    "- 二维坐标轴的含义:\n",
    "  - 回归问题，x轴表示的是特征，y轴表示的是结果\n",
    "  - 分类为题，x、y轴表示的都是特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rbf_svc_2d():\n",
    "    # =====================================================\n",
    "    # 步骤一 : 生成一维线性不可分特征数据\n",
    "    # (1)数据点分布在 x 方向上，无法找到一个分界点，区分两类数据\n",
    "    # (2)只有一个特征，是一维数据，分布在 x 方向，无 y 轴\n",
    "    # =====================================================\n",
    "    x = np.arange(-4, 5, 1)\n",
    "    y = np.array((x >= -2) & (x <= 2), dtype=int)\n",
    "    plt.scatter(x[y == 0], 0 * y[y == 0])\n",
    "    plt.scatter(x[y == 1], 0 * y[y == 1])\n",
    "    plt.show()\n",
    "    \n",
    "    # =======================================================\n",
    "    # 步骤二 : 将一维数据映射到二维空间\n",
    "    # (1)升维，将低维线性不可分的数据，变成高维线性可分\n",
    "    # (2)高斯核会将m*n的数据映射成m*m，便于可视化，这里映射成二维\n",
    "    # =======================================================\n",
    "    def gaussion(x, l):\n",
    "        gamma=1.0\n",
    "        return np.exp(-gamma * (x - l) ** 2)  # x,l 是数字\n",
    "\n",
    "\n",
    "    l1, l2 = -1, 1                        # 固定 2 个地标   <-- (l1, l2)\n",
    "    X_new = np.zeros((len(x), 2))         # 生成 2 维特征   <-- (x1, x2)\n",
    "    for i, data in enumerate(x):\n",
    "        X_new[i, 0] = gaussion(data, l1)  # 与地标 l1 运算  <-- x1\n",
    "        X_new[i, 1] = gaussion(data, l2)  # 与地标 l2 运算  <-- x2\n",
    "\n",
    "    plt.scatter(X_new[y == 0, 0], X_new[y == 0, 1])\n",
    "    plt.scatter(X_new[y == 1, 0], X_new[y == 1, 1])\n",
    "    plt.plot([-0.1, 0.2], [0.2, -0.1], '--', color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rbf_svc_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高斯核\n",
    "- **引入超参数gamma**，调节模型复杂度。gamma越大，模型越复杂，越容易过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def RBFKernelSVC(gamma=1.0):\n",
    "    \"\"\"RBF核SVC\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", gamma=gamma))\n",
    "    ])\n",
    "\n",
    "\n",
    "def RBFKernelSVCTest(gamma=1.0):\n",
    "    rbf_kernel_svc = RBFKernelSVC(gamma=gamma)\n",
    "    rbf_kernel_svc.fit(X, y)\n",
    "    plot_decision_boundary(rbf_kernel_svc, axis=[-1.5, 2.5, -1.0, 1.5])\n",
    "    plot_scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFKernelSVCTest(gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFKernelSVCTest(gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFKernelSVCTest(gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFKernelSVCTest(gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFKernelSVCTest(gamma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFKernelSVCTest(gamma=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM解决回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVR  # 线性\n",
    "from sklearn.svm import SVR  # 线性核\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def linear_svr_test():\n",
    "    # ============================================================\n",
    "    # SVM模型 : 线性、多项式、多项式核、高斯核...\n",
    "    # SVM回归 : 使数据点尽可能多的落在支撑向量之间，引入超参数 epsilon\n",
    "    # ============================================================\n",
    "    def StandardLinearSVR(epsilon=0.1, C=1.0):\n",
    "        \"\"\"线性SVR\"\"\"\n",
    "        return Pipeline([\n",
    "            (\"std_scaler\", StandardScaler()),\n",
    "            (\"linear_svr\", LinearSVR(C=C, epsilon=epsilon))\n",
    "        ])\n",
    "\n",
    "    def PolynomialSVR(epsilon=0.1, degree=2, C=1.0):\n",
    "        \"\"\"多项式SVR\"\"\"\n",
    "        return Pipeline([\n",
    "            (\"ploy\", PolynomialFeatures(degree)),\n",
    "            (\"std_scaler\", StandardScaler()),\n",
    "            (\"linear_svc\", LinearSVR(C=C, epsilon=epsilon))\n",
    "        ])\n",
    "\n",
    "    def PolynomialKernelSVR(epsilon=0.1, degree=2, C=1.0):\n",
    "        \"\"\"多项式核SVR\"\"\"\n",
    "        return Pipeline([\n",
    "            (\"std_scaler\", StandardScaler()),\n",
    "            (\"poly_svr\", SVR(kernel=\"poly\", degree=degree, C=C, epsilon=epsilon))\n",
    "        ])\n",
    "\n",
    "    def RBFKernelSVR(epsilon=0.1, gamma=1.0):\n",
    "        \"\"\"RBF核SVR\"\"\"\n",
    "        return Pipeline([\n",
    "            (\"std_scaler\", StandardScaler()),\n",
    "            (\"rbf_svr\", SVR(kernel=\"rbf\", gamma=gamma, epsilon=epsilon))\n",
    "        ])\n",
    "\n",
    "    def run(X_train, X_test, y_train, y_test, svr_model, title=''):\n",
    "        # 训练、预测\n",
    "        svr_model.fit(X_train, y_train)\n",
    "        y_predict = svr_model.predict(X_test)\n",
    "\n",
    "        # 绘制预测结果\n",
    "        plt.scatter(np.arange(len(y_test)), y_test, color='g')\n",
    "        plt.scatter(np.arange(len(y_predict)), y_predict, color='r', marker='+')\n",
    "        plt.title(label=title)\n",
    "        plt.show()\n",
    "        print(\"R square: \", r2_score(y_test, y_predict))\n",
    "\n",
    "    # ===================\n",
    "    # 步骤一 : 加载数据集\n",
    "    # ===================\n",
    "    boston = load_boston()\n",
    "    X = boston.data\n",
    "    y = boston.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)\n",
    "\n",
    "    # ===================\n",
    "    # 步骤二: 测试 svc\n",
    "    # ===================\n",
    "    run(X_train, X_test, y_train, y_test, StandardLinearSVR(),   \"线性SVR\")\n",
    "    run(X_train, X_test, y_train, y_test, PolynomialSVR(),       \"多项式SVR\")\n",
    "    run(X_train, X_test, y_train, y_test, PolynomialKernelSVR(), \"多项式核SVR\")\n",
    "    run(X_train, X_test, y_train, y_test, RBFKernelSVR(),        \"RBF核SVR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svr_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.15px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
