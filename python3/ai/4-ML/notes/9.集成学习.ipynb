{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原理\n",
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.3, random_state=42)\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1])\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)\n",
    "# 标准化\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train, y_train)\n",
    "X_train = std_scaler.transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "def fit(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model, ':', model.score(X_test, y_test))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "svm_clf = fit(SVC())\n",
    "log_clf = fit(LogisticRegression())\n",
    "dt_clf  = fit(DecisionTreeClassifier(random_state=666))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 投票预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict1 = svm_clf.predict(X_test)\n",
    "y_predict2 = log_clf.predict(X_test)\n",
    "y_predict3 = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.array((y_predict1 + y_predict2 + y_predict3) >= 2, dtype='int')  # 投票: 少数服从多数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 分类问题评价指标:\n",
    "(1) 准确度： accuracy_score\n",
    "(2) 精确度： precision_score   <--- 下面3个指标，用于偏斜数据集\n",
    "(3) 召回率： recall_score\n",
    "(4) F1值 ：  f1_score\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('支持向量机:', accuracy_score(y_test, y_predict1))\n",
    "print('逻辑回归  :', accuracy_score(y_test, y_predict2))\n",
    "print('决策树    :', accuracy_score(y_test, y_predict3))\n",
    "print('集成学习  :', accuracy_score(y_test, y_predict))  # 准确度提高了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "- 单模型，每个算法关注的都是同一份数据，然后对结果进行投票表决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VotingClassifierTest(voting):\n",
    "    def VotingClassifierPrivate(svm_clf, log_clf, dt_clf, voting):\n",
    "        # 1.创建集成学习分类器\n",
    "        voting_clf = VotingClassifier(estimators=[\n",
    "            ('支持向量机:', svm_clf),\n",
    "            ('逻辑回归:', log_clf),\n",
    "            ('决策树:', dt_clf)\n",
    "        ], voting=voting)\n",
    "\n",
    "        # 2.训练\n",
    "        voting_clf.fit(X_train, y_train)\n",
    "\n",
    "        # 3.预测\n",
    "        print(voting_clf.score(X_test, y_test))\n",
    "\n",
    "    if voting == 'soft':\n",
    "        svm_clf = SVC(probability=True)  # 先计算概率\n",
    "        VotingClassifierPrivate(svm_clf, log_clf, dt_clf, voting='soft')\n",
    "    else:\n",
    "        svm_clf = SVC(probability=False)\n",
    "        VotingClassifierPrivate(svm_clf, log_clf, dt_clf, voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Voting\n",
    "- **投票:** 少数服从多数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VotingClassifierTest(voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting\n",
    "- **投票:** 引入权重，要求`模型能计算概率`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VotingClassifierTest(voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bagging\n",
    "- **原理:** 创建更多的子模型，让子模型彼此具有差异性，且不需要很高的准确率，最终模型整体的准确率却是很高的\n",
    "  - 子模型差异性: \n",
    "    - 只关注一部分数据: max_samples\n",
    "    - 只关注一部分特征: max_features\n",
    "    - 只关注一部分数据+特征: max_samples, max_features\n",
    "  - 取样方式:\n",
    "    - 放回取样: bootstrap=True, bootstrap_features=True\n",
    "    - 不放回取样: bootstrap=False, bootstrap_features=False\n",
    "  - oob(out of bag)\n",
    "    - 放回取样，导致一部分样本很有可能没有取到。可以使用这部分没有取到的样本做测试/验证。设置: oob_score=True\n",
    "  - 并行化处理\n",
    "    - 每个模型都是独立的，可以并行。设置: n_jobs=?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 只关注一部分数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                                n_estimators=500, # 创建 500 个子模型\n",
    "                                max_samples=100,  # 每个子模型只关注 100 个数据\n",
    "                                bootstrap=True,   # True: 放回取样\n",
    "                                oob_score=True)   # True: 放回取样时，使用未取到的数据点进行预测\n",
    "\n",
    "bagging_clf.fit(X, y)\n",
    "bagging_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 只关注一部分特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_subspaces_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                                          n_estimators=500,          # 创建 500 个子模型\n",
    "                                          max_features=1,            # 每个子模型只关注 1 个特征\n",
    "                                          bootstrap_features=True,   # True: 放回取样\n",
    "                                          oob_score=True)            # True: 放回取样时，使用未取到的数据进行预测\n",
    "\n",
    "bagging_subspaces_clf.fit(X, y)\n",
    "bagging_subspaces_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 只关注一部分数据+特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_patches_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                                        n_estimators=500,          # 创建 500 个子模型\n",
    "                                        # 1.random samples\n",
    "                                        max_samples=100,           # 每个子模型只关注 100 个数据\n",
    "                                        bootstrap=True,            # True: 放回取样\n",
    "                                        # 2.random features\n",
    "                                        max_features=1,            # 每个子模型只关注 1 个特征\n",
    "                                        bootstrap_features=True,   # True: 放回取样\n",
    "                                        # 3.out of bag\n",
    "                                        oob_score=True)            # True: 放回取样时，使用未取到的数据进行预测\n",
    "\n",
    "bagging_patches_clf.fit(X, y)\n",
    "bagging_patches_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林\n",
    "- 属于集成学习\n",
    "- 集成了bagging和决策树\n",
    "- 每个子模型都是决策树，只关注一部分数据or特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=500,  # 创建 500 个子模型\n",
    "                                oob_score=True,    # True: 放回取样时，使用未取到的数据进行预测\n",
    "                                random_state=666,\n",
    "                                n_jobs=-1)\n",
    "print(rf_clf.fit(X, y))\n",
    "print(rf_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra-Trees\n",
    "- 与随机森林不同的是：每棵决策树在节点划分上，采用完全随机的维度和阈值，而随机森林会搜索最优的维度和阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_clf = ExtraTreesClassifier(n_estimators=500,  # 创建 500 个子模型\n",
    "                              oob_score=True,    # True: 放回取样时，使用未取到的数据进行预测\n",
    "                              bootstrap=True,    # True: 放回取样\n",
    "                              random_state=666,\n",
    "                              n_jobs=-1)\n",
    "print(et_clf.fit(X, y))\n",
    "print(et_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "- 相比于bagging：子模型之间不是独立的，而是依赖增强的关系\n",
    "\n",
    "## Ada Boosting\n",
    "- 每个子模型，**更关注**上个子模型犯的错\n",
    "- 每轮训练，会调整数据权重，将注意力集中在模型分割错误的数据上【增大权重】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=500)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "ada_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT\n",
    "- 每个子模型，**只关注**上个子模型犯的错\n",
    "- 每轮训练，将上一轮训练的真实值-预测值，(误差值)作为这轮的真实值(目标值)\n",
    "- 原理：梯度下降 + boosting + 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(max_depth=2, n_estimators=500)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "- 原理：二阶泰勒展开 + boosting + 决策树 + 正则化\n",
    "- 泰勒展开式：f(x) = f(x0) + f'(x0)*(x-x0) + f''(x0)/2!*(x-x0)^2 + ... + f(n)(x0)/n!*(x-x0)^n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集成学习解决回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_reg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, oob_score=True)\n",
    "bagging_reg.fit(X, y)\n",
    "bagging_reg.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators=500, oob_score=True)\n",
    "rf_reg.fit(X, y)\n",
    "rf_reg.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_reg = ExtraTreesRegressor(n_estimators=500, oob_score=True, bootstrap=True)\n",
    "et_reg.fit(X, y)\n",
    "et_reg.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=500)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "ada_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_reg = GradientBoostingRegressor(n_estimators=500)\n",
    "gb_reg.fit(X_train, y_train)\n",
    "gb_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.513px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
